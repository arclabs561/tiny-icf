# Universal Support: Symbols, Emojis, and Multilingual

## Extensions Implemented

### 1. âœ… Multilingual Typo Patterns

**File**: `src/tiny_icf/symbol_augmentation.py`

**Supported Languages**:
- **Spanish (es)**: Ã¡â†’a, Ã©â†’e, Ã­â†’i, Ã³â†’o, Ãºâ†’u, Ã±â†’n, Ã¼â†’u
- **French (fr)**: Ã â†’a, Ã¢â†’a, Ã©â†’e, Ã¨â†’e, Ã§â†’c, etc.
- **German (de)**: Ã¤â†’a, Ã¶â†’o, Ã¼â†’u, ÃŸâ†’ss
- **Russian (ru)**: Cyrillicâ†’Latin common mistakes

**Features**:
- Automatic language detection
- Language-specific typo patterns
- Accentedâ†’unaccented substitutions (common typos)

### 2. âœ… Random Symbols Support

**File**: `src/tiny_icf/symbol_augmentation.py`

**Handles**:
- Punctuation: `!`, `@`, `#`, `$`, `%`, `^`, `&`, `*`, etc.
- Special chars: `-`, `_`, `=`, `+`, `[`, `]`, `{`, `}`, etc.
- Web text patterns: symbols at end (usernames, tags)
- Symbol substitutions (typo-like)

**Augmentation**:
- Add symbols at word boundaries (common in web text)
- Replace characters with similar symbols
- Configurable probability (default: 5%)

### 3. âœ… Emoji/Emoticon Support

**File**: `src/tiny_icf/symbol_augmentation.py` + `scripts/download_emoji_frequencies.py`

**Handles**:
- **Unicode Emojis**: ğŸ˜€, ğŸ˜‚, â¤ï¸, ğŸ‘, etc. (50+ common ones)
- **Text Emoticons**: `:)`, `:(`, `;)`, `:D`, `:P`, `<3`, `xD`, etc.
- **Frequency Data**: Created default frequency list
- **Extraction**: Can extract from typo corpus

**Augmentation**:
- Add emojis at end (like "hello ğŸ˜€")
- Emojis in middle (less common)
- Configurable probability (default: 2%)

### 4. âœ… Byte-Level Processing (Already Handles Everything)

**Key Insight**: Our byte-level CNN already handles:
- âœ… **All Unicode**: UTF-8 encoding covers all languages
- âœ… **Emojis**: Multi-byte sequences handled correctly
- âœ… **Symbols**: Any byte sequence works
- âœ… **Multilingual**: No language-specific tokenization needed

**Why This Works**:
- Input: Raw UTF-8 bytes (0-255)
- Model sees: Byte sequences, not characters
- Handles: Any language, emoji, symbol automatically

## Usage

### Universal Augmentation

```python
from tiny_icf.symbol_augmentation import UniversalAugmentation
from pathlib import Path

aug = UniversalAugmentation(
    typo_corpus_path=Path("data/typos/github_typos.csv"),
    symbol_prob=0.05,      # 5% symbol augmentation
    emoji_prob=0.02,        # 2% emoji augmentation
    multilingual_prob=0.1,  # 10% multilingual patterns
    keyboard_prob=0.15,     # 15% keyboard typos
)

# Works on any language/symbol/emoji
aug("hello")      # English
aug("cafÃ©")       # French (might become "cafe")
aug("Ğ¿Ñ€Ğ¸Ğ²ĞµÑ‚")     # Russian
aug("hello ğŸ˜€")    # With emoji
```

### Universal Dataset

```python
from tiny_icf.data_universal import UniversalICFDataset, load_frequency_list_with_emojis

# Load with emojis
word_counts, total = load_frequency_list_with_emojis(
    Path("data/combined_frequencies.csv"),
    Path("data/emojis/emoji_frequencies.csv"),
)

# Create universal dataset
dataset = UniversalICFDataset(
    word_icf_pairs,
    typo_corpus_path=Path("data/typos/github_typos.csv"),
    emoji_freq_path=Path("data/emojis/emoji_frequencies.csv"),
    include_symbols=True,
    include_emojis=True,
)
```

## Data Created

### Emoji Frequencies
- `data/emojis/emoji_frequencies.csv`: 50+ emojis + text emoticons
- Based on common web usage patterns
- Can be extracted from typo corpus

## Why Byte-Level is Perfect

### Handles Everything Automatically

1. **Multilingual**: UTF-8 bytes encode all languages
   - Spanish: `cafÃ©` â†’ bytes `[99, 97, 102, 195, 169]`
   - Russian: `Ğ¿Ñ€Ğ¸Ğ²ĞµÑ‚` â†’ Cyrillic bytes
   - Chinese: `ä½ å¥½` â†’ Multi-byte sequences

2. **Emojis**: Multi-byte UTF-8 sequences
   - `ğŸ˜€` â†’ `[240, 159, 152, 128]` (4 bytes)
   - Model learns: "4-byte sequences = emojis"

3. **Symbols**: Any byte value (0-255)
   - `!@#$%` â†’ byte sequences
   - Model learns: "non-alphanumeric bytes = symbols"

4. **No Tokenization Needed**: 
   - No language-specific rules
   - No emoji detection logic
   - Just raw bytes â†’ model learns patterns

## Testing

```bash
# Test universal augmentation
python -c "
from tiny_icf.symbol_augmentation import UniversalAugmentation
from pathlib import Path

aug = UniversalAugmentation(
    Path('data/typos/github_typos.csv'),
    symbol_prob=1.0,
    emoji_prob=1.0,
)

words = ['hello', 'cafÃ©', 'Ğ¿Ñ€Ğ¸Ğ²ĞµÑ‚', 'test123']
for w in words:
    print(f'{w} -> {aug(w)}')
"
```

## Status

âœ… **Multilingual**: Language-specific typo patterns
âœ… **Symbols**: Random symbol augmentation
âœ… **Emojis**: Emoji/emoticon support
âœ… **Byte-Level**: Handles everything automatically
âœ… **Frequency Data**: Emoji frequencies created

**The model is now truly universal!**

